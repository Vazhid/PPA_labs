Современные методы синтеза речи активно используют достижения в области глубокого обучения и нейронных сетей. Вот некоторые из них:

1. **Tacotron 2**: Это архитектура, которая использует рекуррентные нейронные сети (RNN) и преобразует текст в спектрограммы, которые затем преобразуются в аудио с помощью нейронного вокодера, такого как WaveNet.

2. **WaveNet**: Это генеративная модель, основанная на сверточных нейронных сетях, которая может генерировать высококачественный аудиосигнал.

3. **FastSpeech и FastSpeech 2**: Эти модели предлагают более быстрый и стабильный синтез речи по сравнению с Tacotron, используя трансформеры для генерации спектрограмм.

4. **VITS (Variational Inference Text-to-Speech)**: Это более новая модель, которая объединяет в себе преимущества Tacotron и WaveNet, обеспечивая высокое качество синтеза речи.

5. **Glow-TTS**: Использует нормализующие потоки для генерации спектрограмм, что позволяет добиться более стабильного и быстрого синтеза.

Для поиска актуальных статей по теме синтеза речи для малоресурсных языков, включая лезгинский, рекомендую использовать следующие ресурсы:

- **Google Scholar**: Введите ключевые слова, такие как "speech synthesis low-resource languages" и установите фильтр по дате публикации после 2020 года.
- **arXiv**: Это репозиторий препринтов, где можно найти много современных исследований. Используйте аналогичные ключевые слова.
- **IEEE Xplore**: Здесь можно найти статьи из конференций и журналов по теме синтеза речи.

Вот несколько примеров статей, которые могут быть полезны:

1. **"FastSpeech 2: Fast and High-Quality End-to-End Text to Speech"** (2020) - статья о модели FastSpeech 2.
2. **"VITS: Variational Inference Text-to-Speech"** (2021) - статья о модели VITS.
3. **"Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search"** (2020) - статья о модели Glow-TTS.

Эти статьи могут дать вам представление о современных подходах и методах, которые можно адаптировать для работы с малоресурсными языками.
