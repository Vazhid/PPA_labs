Разработка TTS для лезгинского языка требует тщательной оценки качества синтеза. Приведу **метрики, инструменты и практические рекомендации**, адаптированные под особенности лезгинского (агглютинативность, богатая фонетика, отсутствие эталонных корпусов).

---

## **1. Методы записи данных**
### **Сравнение студийной записи и краудсорсинга**
| Критерий               | Студийная запись         | Краудсорсинг              |
|------------------------|--------------------------|---------------------------|
| **Качество аудио**     | Высокое (16–44 kHz, без шума) | Разное (может потребоваться очистка) |
| **Диалекты**           | Контролируемый отбор      | Естественное разнообразие |
| **Стоимость**          | Дорого (~500–1000 руб./час) | Дешево (краудфандинг/волонтеры) |
| **Пример**             | [Avar Studio Corpus](https://ilab.media) | [Common Voice](https://commonvoice.mozilla.org) |

**Рекомендация:**  
Комбинируйте оба метода:  
- **10–20% студийных записей** (эталон для оценки).  
- **80–90% краудсорсинга** (например, через Telegram-бот или [SpeechCollector](https://github.com/speechcollector)).  

---

## **2. Инструменты для автоматической разметки**
### **(A) Для транскрипции текста**
| Инструмент             | Точность для лезгинского | Необходимая доработка     | Python-интеграция       |
|------------------------|--------------------------|---------------------------|-------------------------|
| **Whisper** (OpenAI)   | ~80–90% (если есть данные для finetune) | Требует постобработки     | [`whisper`](https://github.com/openai/whisper) |
| **Vosk**               | ~70–80% (есть [модель для дагестанских языков](https://alphacephei.com/vosk/models)) | Нужен словарь             | [`vosk`](https://github.com/alphacephei/vosk-api) |
| **Mozilla DeepSpeech** | Низкая (нет поддержки)   | Не рекомендуется          | —                       |

### **(B) Для выравнивания (forced alignment)**
| Инструмент             | Требования               | Скрипты для Python        |
|------------------------|--------------------------|---------------------------|
| **Montreal Forced Aligner (MFA)** | Нужен G2P для лезгинского | [`mfa`](https://montreal-forced-aligner.readthedocs.io/) |
| **Gentle**             | Работает с Whisper       | [`gentle`](https://github.com/lowerquality/gentle) |
| **PyTorch-Kaldi**      | Сложная настройка        | —                         |

**Рекомендация:**  
1. **Транскрибируйте Whisper** → **очищайте вручную** (например, в [ELAN](https://archive.mpi.nl/tla/elan)).  
2. **Выравнивайте через MFA** (если есть G2P) или **Gentle**.  

---

## **3. Минимальный объем данных для старта**
| Сценарий                | Требуемый объем | Качество синтеза          |
|-------------------------|-----------------|---------------------------|
| **Zero-Shot TTS (YourTTS, XTTS)** | 5–10 мин на диктора | Среднее (роботизированное) |
| **Few-Shot Fine-Tuning** | 1–2 часа        | Приемлемое (но с артефактами) |
| **Полноценное обучение** | 5–10 часов      | Хорошее (если данные чистые) |
| **Студийный эталон**    | 1 час           | Для оценки метрик          |

**Важно:**  
- Для **агглютинативных языков** (как лезгинский) нужно больше данных для покрытия морфем.  
- Лучше 5 часов **чистых данных**, чем 20 часов с шумом.  

---

## **4. Метрики оценки качества TTS**
### **(A) Объективные метрики (Python-скрипты)**
| Метрика                  | Описание                  | Python-библиотека         | Готовый код              |
|--------------------------|---------------------------|---------------------------|--------------------------|
| **MCD (Mel-Cepstral Distortion)** | Различие в мел-спектрах | [`pymcd`](https://github.com/stevetjoa/pymcd) | [Пример](https://github.com/chenqi008/pymcd) |
| **F0-RMSE**              | Ошибка по тону (pitch)    | [`parselmouth`](https://parselmouth.readthedocs.io/) | [Код расчета](https://github.com/YannickJadoul/Parselmouth) |
| **WER (Word Error Rate)** | Сравнение с эталоном через ASR | [`jiwer`](https://github.com/jitsi/jiwer) | [Пример](https://github.com/huggingface/evaluate/blob/main/metrics/wer/wer.py) |
| **Duration MSE**         | Ошибка длительностей      | `numpy` + ручной расчет   | —                        |

### **(B) Субъективные метрики (если нет носителей)**
- **MOS (Mean Opinion Score)** через краудсорсинг (например, [Amazon Mechanical Turk](https://www.mturk.com/)).  
- **ABX-тесты** (слушатель выбирает лучший вариант).  

**Скрипты для расчета:**  
- Готовый код для MCD/F0: [TTS-Evaluation-Toolkit](https://github.com/coqui-ai/TTS-Evaluation).  
- WER: [HuggingFace Evaluate](https://huggingface.co/docs/evaluate/index).  

---

## **5. Готовые решения для лезгинского**
- **Если нет G2P:** Используйте [Epitran](https://github.com/dmort27/epitran) для грубой транслитерации.  
- **Для разметки:** [SpeechMatcher](https://github.com/speechmatcher) (автоматическая очистка аудио).  
- **Для синтеза:** Дообучите [XTTS-v2](https://github.com/coqui-ai/TTS) на 5–10 часах данных.  

---

## **Выводы**
1. **Запись данных:**  
   - Комбинируйте **студийные записи (1–2 часа)** + **краудсорсинг (5+ часов)**.  
2. **Разметка:**  
   - **Whisper → MFA/Gentle → ручная проверка**.  
3. **Оценка:**  
   - **MCD, F0-RMSE, WER** (готовые скрипты на Python).  
4. **Минимальный объем:**  
   - **1 час** для тестов, **5+ часов** для рабочей модели.  

Если у вас есть доступ к носителям, проведите **субъективную оценку (MOS)**. Для автоматизации используйте [TTS-Evaluation-Toolkit](https://github.com/coqui-ai/TTS-Evaluation).